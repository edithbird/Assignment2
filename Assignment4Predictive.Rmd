---
title: 'Predictive: Unit 4 Quiz and Homework'
author: "Christine Iyer"
date: "March 18, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Quiz:

**1.	Explain what type of smoothing model can be used if a time series contains a trend.**

Moving Average can be used for data that contains trend, if the data series is detrended. One way it can be trended is by using differencing with a lag = 1. If the data reveals an exponential or quadratic trend, a second round of differencing with a lag = 1 may be necessary. 

Simple Exponential Smoothing, like Moving Average, is for forecasting time series that have no trend or seasonality. However if the data series has been detrended with differencing, simple exponential smoothing may be a good model. 

Advanced Expoential Smoothing models are built to accomodate data series with trend. In particular, double exponential smoothing, aka, Holt's linear trend model, the assumption is that the trend can change over time, it's not just assuming the trend is global. Thr trend is estimated from the data and is consistently updated with more data as it becomes available. Holt's model can accomodate data with additive and multiplicative trends. 

A second exponential smoothing method called Holt Winter's is appropriate for data series with trend and seasonality. Again, it can accomodate both additive and multiplicative trends. 

2.	Explain how the value of alpha affects the simple exponential smoothing method.

$\alpha$, a user chosen parameter, operates as a constant and is valued between 0-1; it determines the model's rate of learning, i.e., how much influence the most recent values in the time series have on the forecast. (Alpha operates simliarly to the user determined W, or window length, in moving averages in that it dictates the importance of newer information in generating the forecast.) A value close to 1, causes the model to learn faster,  meaning that the the most recent data has the greatest impact on the forecast. Conversely, a value close to 0 indicates the model  learns slowly and the recent data have little impact while past data have the greatest influence. 

Because $\alpha$ is far from zero, the level adapts locally,



**3.	Explain what it means if the two smoothing constants in double exponential smoothing, alpha and beta, are closer to 1.**

The $\alpha$ constant is used to smooth the time series that exhibits stationarity. As explained above, in exponential smoothing, an $\alpha$ close to one means the model learns quickly and the most recent data in the series has the greatest impact on the forecast. 

$\beta$ is a second smoothing constant that is used in addition to $\alpha$ and it is used in double exponential smoothing, or, Holt Winter's models for **trend** smoothing. A higher $\beta$ value, one that is closer to 1, is chsen when less smoothing is desired; therefore, more weight is plaved on the recent data.  

**4.	Describe how you would use differencing to remove a trend from a time series dataset.**

If a forecaster observes a trend in the time series data, but would like to see how a moving average forecast would perform in terms of predictive accuracy, he would have to use differencing to remove this trend. Moving averages are typically forecasting tools for data that exhibits stationarity, not trend or seasonality. In order to adapt the moving average forecast for data with a linear trend, the user first performs differencing with a lag on 1. Once this is done, a plot of the data will show no visible trend. If the initial data set shows a quadratic or exponential trend, another round of lag-1 differencing is required on the already differenced data. Performing differencing with a lag of 1 is simply done by taking the difference between every 2 consecutive values for the series. 

"One advantage of differencing over other methods (e.g., a regression with a trend - see Chapter 6) is that differencing does not assume that the trend is global: i.e., the trend shape is fixed throughout the entire period."

Shmueli, Galit; Lichtendahl Jr, Kenneth C.. Practical Time Series Forecasting with R: A Hands-On Guide [2nd Edition] (Practical Analytics) (Page 85). Axelrod Schnall Publishers. Kindle Edition. 



**5.	When using moving average for forecasting, how should you choose the appropriate window size, w?**

When using the moving average forecasting model, the user gets to choose the width of the trailing moving average window, or **W**. Striking a balance between under and over forecasting may require some trial and error. A first step is to visualize the data series. If the series shows seasonal pattern, a W of the length of the seasonal cycle may be a good choice. 

Domain knowledge regarding how fast the series changes and regarding the relevance of past observations will assist the forecaster in making this decision. 

Trial and error is also part of the decision. Seeing how the model performs with different window widthe allows comparison of the errors and the performance charts. It is also important to not overfit the model to the data.  


#Homework:

Please answer Chapter 5, questions 2, 5, and 8 from the text (p. 108 - 116).




##2. 
Relationship between Moving Average and Exponential Smoothing: Assume that we apply a moving average to a series, using a very short window span. If we wanted to achieve an equivalent result using simple exponential smoothing, what value should the smoothing constant take?

A value very close to 1. 

#Testing for question 2 on HW

**trailing ma**

```{r}
ridership <- read.csv("Amtrak.csv")
##convert data to a time series
ridership.ts <- ts(ridership$Ridership_in_thousands, start = c(1991,1), end = c(2004, 3), frequency = 12)
```


```{r}
library(zoo)
library(forecast)
library(ggplot2)
#3 year validation period window
nValid <- 36
#training period
nTrain <- length(ridership.ts) - nValid
#training window
train.ts <- window(ridership.ts, start = c(1991, 1), end = c(1991, nTrain))
#validation window
valid.ts <- window(ridership.ts, start = c(1991, nTrain + 1), end = c(1991, nTrain + nValid))
#trailing moving average of training period
ma.trailing <- rollmean(train.ts, k = 12, align = "right")
#last value because want a lag 
#last.ma <- tail(ma.trailing, 1)
#ma.trailing.pred <-ts(rep(last.ma, nValid), start = c(1991, nTrain + 1), end = c(1991, nTrain + nValid), freq = 12)
forecast.ma.trailing <- forecast(ma.trailing, h = nValid, level = 0)
accuracy(forecast.ma.trailing, valid.ts)
```

**ses**
```{r}
ses.ridership <- ets(train.ts, model = "ANN", alpha = .98)


ses.pred <- forecast(ses.ridership, h = nValid, level = 0)
accuracy(ses.pred, valid.ts)
```


##5. 
Forecasting Department Store Sales


```{r}
library(dplyr)
library(forecast)
DeptSales <- read.csv("DeptStoreSales.csv", header = TRUE, stringsAsFactors = FALSE)

DeptSales$Yr_Qtr <- c("Year 1 Q-1", "Year 1 Q-2", "Year 1 Q-3", "Year 1 Q-4", "Year 2 Q-1", "Year 2 Q-2", "Year 2 Q-3", "Year 2 Q-4", "Year 3 Q-1", "Year 3 Q-2", "Year 3 Q-3", "Year 3 Q-4", "Year 4 Q-1", "Year 4 Q-2", "Year 4 Q-3", "Year 4 Q-4", "Year 5 Q-5", "Year 5 Q-2", "Year 5 Q-3", "Year 5 Q-4", "Year 6 Q-1", "Year 6 Q-2", "Year 6 Q-3", "Year 6 Q-4")
DeptSales <- DeptSales %>% select(Yr_Qtr, Sales)
head(DeptSales)
DeptSales.ts <- ts(DeptSales$Sales, start = c(1,1), frequency = 4)
#linear trend line
DeptSales.Linear <- tslm(DeptSales.ts ~ trend)
sales.lm.pred <- forecast(DeptSales.Linear, h = nValid, level = 0)
#quadratic trend line
DeptSales.quad <- tslm(DeptSales.ts ~ trend + I(trend^2))
sales.quad <- forecast(DeptSales.quad, h = nValid, level = 0)


yrange <- range(DeptSales.ts)

plot(c(1,6), yrange, type = "n", xlab = "Year", ylab = "Dept Store Sales (thousands)", bty = "l", xaxt = "n", yaxt = "n", lwd = 2)

axis(1, at = seq(1, 6, 1), labels = format(seq(1, 6, 1)))
axis(2, at = seq(40000, 105000, 10000), labels = format(seq(40, 105, 10)), las = 2)
lines(DeptSales.Linear$fitted , col = "blue", lwd = 2)
lines(DeptSales.quad$fitted, col = "red", lwd = 2)
legend(1, 100, c("Dept Store Sales", "Linear Trend", "Quad Trend"), lty = c(1,1,1), col = c("green", "blue", "red"), lwd = c(2,2,2), bty = "n")

#plot(DeptSales.ts, type = "n", xlab = "Year", ylab = "Sales", ylim = c(25000, 105000), bty = "l", col = 3, type = "o", lwd = 2, xaxt = "n", yaxt = "n") 
```


```{r}
yrange <- range(DeptSales.ts)
#plot
plot(c(1,6), yrange, type = "n", xlab = "Year", ylab = "Dept Store Sales (thousands)", bty = "l", xaxt = "n", yaxt = "n")
lines(DeptSales.ts, bty = "l", lwd = 2)
axis(1, at = seq(1, 6, 1), labels = format(seq(1, 6, 1)))
axis(2, at = seq(40000, 105000, 10000), labels = format(seq(40000, 105000, 10000)), las = 2)
lines(DeptSales.Linear$fitted , col = "blue", lwd = 2)
lines(DeptSales.quad$fitted, col = "green", lwd = 2)
legend(1, 105000, c("Dept Store Sales", "Linear Trend", "Quadratic Trend"), lty = c(1,1,1), col = c("black", "blue", "green"), lwd = c(2,2,2), bty = "n")






```



lines(trailingMA, col = "blue", lwd = 2)
lines(centeredMA, col = "green", lwd = 2)
legend(1, 100, c("Dept Store Sales", "Trailing Moving Average", "Centered Moving Average"), lty = c(1,1,1), col = c("black", "blue", "green"), lwd = c(2,2,2), bty = "n")


```{r}
par(mfrow = c(1, 2)) 
plot(DeptSales.ts/ 1000, xlab = "Time", ylab = "Dept Store Sales (thousands)", ylim = c(25, 100), 
     bty = "l", main = "Dept Store Sales")
DeptSales.ts.zoom <- window(DeptSales.ts/1000, start = c(1, 1), end = c(2, 4))
plot(#c(1,4), 
     DeptSales.ts.zoom, type = "n", xlab = "Quarter", ylab = "Dept Store Sales (thousands)", bty = "l", xaxt = "n", yaxt = "n", lwd = 2)

axis(1, at = seq(1,8, 1), labels = format(seq(1, 8, 1)))
axis(2, at = seq(23, 105, 10), labels = format(seq(23, 105, 10)), las = 2)
lines(DeptSales.ts.zoom , col = "blue", lwd = 2)

```


```{r, eval=FALSE, include=FALSE}
yrange <- range(DeptSales.ts)
#linear summary
summary(DeptSales.Linear)
#Quad Summary
summary(sales.quad)
par(mfrow = c(1, 2)) 
#plot series
plot(DeptSales.ts/ 1000, xlab = "Time", ylab = "Dept Store Sales (thousands)", #ylim = c(40, 100), 
     bty = "l", main = "Dept Store Sales")



#plot fitted trend line
#lines(DeptSales.lm$fitted, lwd = 2) 
#zoom into 4 years
#first create window
DeptSales.ts.zoom <- window(DeptSales.ts/1000, start = c(1, 1), end = c(1, 4))
#plot zooned in data

plot(c(1,2), type = "n", xlab = "Year", ylab = "Dept Store Sales (thousands)", bty = "l", xaxt = "n", yaxt = "n", lwd = 2)

axis(1, at = seq(1, 2, 1), labels = format(seq(1, 2, 1)))
axis(2, at = seq(25, 105, 10), labels = format(seq(40, 105, 10)), las = 2)

plot(DeptSales.ts.zoom/ 1000, xlab = "Time", ylab = "Dept Store Sales (thousands)", ylim = c(25, 105), bty = "l", main = "Dept Store Sales \nYear 1") 


```



```{r, echo=TRUE}
library(ggplot2)

bold.text <- element_text(face = "bold", color = "black", size = 10)
legendT <- "Legend"

bold.italic <- element_text(face = "bold.italic", color = "black", size = 11)
ggseasonplot(DeptSales.ts/1000, ylab = "Dept Store Sales (thousands)", xlab = "Quarter",  main = "Seasonal Plot for Dept Store Sales") + 
  theme_bw() +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()) + 
  guides(fill = guide_legend(reverse = TRUE)) +  
  theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
  
  ## axis.text.x for x axis only
theme(axis.text = bold.text) +
theme(title = bold.italic, axis.title = bold.italic) +
  geom_line(size = 1) +
  theme(plot.title = element_text(hjust = 0.5)) 

```

**Ridership boken out by month**

```{r}

par(oma = c(0, 0, 0, 2))
xrange <- c(1992,2004)
yrange <- range(ridership.ts)
plot(xrange, yrange, type="n", xlab="Year", ylab="Monthly Plot Dept Store Sales ", bty="l", las=1)
colors <- rainbow(12) 
linetype <- c(1:12) 
plotchar <- c(1:12)
axis(1, at=seq(1992,2004,1), labels=format(seq(1992,2004,1)))
for (i in 1:12) { 
  currentMonth <- subset(ridership.ts, cycle(ridership.ts)==i)
  lines(seq(1992, 1992 +length(currentMonth)-1,1), currentMonth, type="b", lwd=1,
      lty=linetype[i], col=colors[i], pch=plotchar[i]) 
} 
title("Ridership Broken Out by Month")
legend(2002.35, 80, 1:12, cex=0.8, col=colors, pch=plotchar, lty=linetype, title="Month", xpd=NA)

```

a. Which of the following methods would not be suitable for forecasting this series. Explain why or why not for each one.

**Moving average of raw series** This is not a method for forecasting because it does not accomodate trend or seasonality, 2 components in this data series.  

Forecast the data with a trailing moving average

```{r}

validLength <- 4
trainLength <- length(DeptSales.ts) - validLength
salesTrain <- window(DeptSales.ts, end = c(1, trainLength))
salesValid <- window(DeptSales.ts, start = c(1, trainLength + 1))

#trailing moving average
trailingMA <- rollmean(salesTrain, k = 3, align = "right")
#first value of the moving average
trailingMA[1]
#centered moving average
centeredMA <- ma(salesTrain, order = 3)

#forecast trailing moving average
forecast(trailingMA, h = validLength)

yrange <- range(DeptSales.ts)
#plot
plot(c(1,6), yrange, type = "n", xlab = "Year", ylab = "Dept Store Sales (thousands)", bty = "l", xaxt = "n", yaxt = "n")
lines(DeptSales.ts, bty = "l", lwd = 2)
axis(1, at = seq(1, 6, 1), labels = format(seq(1, 6, 1)))
yrange
#seq() from, to, by in increments
axis(2, at = seq(40000, 105000, 10000), labels = format(seq(40, 105, 10)), las = 2)
lines(trailingMA, col = "blue", lwd = 2)
lines(centeredMA, col = "green", lwd = 2)
legend(1, 100, c("Dept Store Sales", "Trailing Moving Average", "Centered Moving Average"), lty = c(1,1,1), col = c("black", "blue", "green"), lwd = c(2,2,2), bty = "n")
```

**Accuracy of the moving average forecast on the raw series.**


```{r}
accuracy(forecast(trailingMA, h = validLength))
```


* **Moving average of deseasonalized series** 

Moving average forecasting is for data that demonstrates stationarity, it should not have trend or seasonality. The six year series of department store quarterly sales has trend and seasonality components. Deseasonalizing the series in not adquate for forecasting with the moving average because the series still has a trend. The series would have to be detrended with differencing before a moving average could be used for forecasting. 

```{r}
#deseasonalized Dept Store Sales with lag 4 differencing
lag4diff <- diff(DeptSales.ts, lag=4)
#valid
lag4nValidLength <- 4
#training set
lag4TrainLength <- length(lag4diff) - lag4nValidLength
lag4TrainWindow <- window(lag4diff, end = c(1, lag4TrainLength))
lag4ValidWindow <- window(lag4diff, start = c(1, lag4TrainLength + 1))


trailingMADeSeason <- rollmean(lag4TrainWindow, k = 3, align = "right")
accuracy(forecast(trailingMADeSeason, h = lag4nValidLength))


```


```{r}
#set up a plot with 2 rows and 2 columns
par(mfrow = c(2,2))
#plot the original
plot(DeptSales.ts, ylab = "Dept Store Sales", xlab = "Year", bty = "l", main = "Dept Store Sales")
#lag 4 differencing
lag4diff <- diff(DeptSales.ts, lag=4)
#plot the lag-4 difference
plot(lag4diff,  ylab="Lag-4", xlab="Year", bty="l", main="Lag-4 Differencing \nDe-Seasonalized")
#lag-1 differencing for detrending
lag1diff <- diff(DeptSales.ts, lag=1)

#plot the lag-1 difference for detrending
plot(lag1diff,  ylab="Lag-1", xlab="Year", bty="l", main="Lag-1 Differencing \nDe-trended")

#double differenced
doubleDiff <- diff(diff(DeptSales.ts, lag = 4), lag = 1)
#plot double differenced
plot(doubleDiff,  ylab="Lag-4, then Lag-1", xlab="Year", bty="l", main="Dept Sales Twice-Differenced \nDe-Seasonalized \nDe-Trended")


```

* **Simple exponential smoothing of the raw series** 

Simple Exponential Smoothing, like Moving Average, is for forecasting time series that have no trend or seasonality. Therefore applying the forecasting method on the raw data series would not be suitable for this task. However, if the data series has been detrended and deseasonalized with double differencing, simple exponential smoothing may be a good model. Below is a table showing the optimal alpha and the appropriate model, 0.9672 and "MNM" respectively and graph showing the ets forecast and fit. 

```{r}
DeptSales
```

**If we use the simple exponential smoothing model "ANN" to forecast with an alpha of 0.2, we see an overly smooth model that is under and over forecasting.**

```{r}
nValid <- 4
nTrain <- length(DeptSales.ts) - nValid
salesTrain <- window(DeptSales.ts, end = c(1, nTrain +1))
salesValid <- window(DeptSales.ts, start = c(1, nTrain + 1))
sesSales <- ets(salesTrain, model = "ANN", alpha = 0.2)
sesSales

yrange <- range(DeptSales.ts)
# Set up the plot
plot(c(1, 7), c(yrange[1], yrange[2] + 0.25
                ), type="n", xlab="Year", ylab="Sales (thousands)", bty="l", xaxt="n", yaxt="n")

# Add the time series training set
lines(DeptSales.ts, bty="l")

# Add the x-axis
axis(1, at = seq(1, 7, 1), labels = format(seq(1, 7, 1)))

# Add the y-axis
axis(2, at = seq(40000, 120000, 10000), labels = format(seq(40, 120, 10)), las = 2)

# Add the fitted values to the training set
lines(sesSales$fitted, col="red", lwd=1)

# Use the forecast() function to generate forecasts for the validation period
sesSalesPredictions <- forecast(sesSales, h=validLength, level=0)


# Print them out
sesSalesPredictions

# Add them to the plot
lines(sesSalesPredictions$mean, col="red", lwd=2, lty=2)

# # Add the "visual breakpoints"
abline(v=6)
arrows(1, 103000, 6, 103000, code=3, length=0.1)
text(3, 98000, "Training")
abline(v=7)
arrows(6, 103000, 7, 103000, code=3, length=0.1)
text(6.5, 98000, "Validation")

```


**We can let the ets function choose the best model. The table below shows the error, alpha, correct ses model, and the plot of that fit and forecast against the actual data. This model is a **fast learner** because the most recent data has the most impact on the future. **

```{r}
sesSales <- ets(salesTrain, model = "ZZZ")
sesSales

yrange <- range(DeptSales.ts)
# Set up the plot
plot(c(1, 7), c(yrange[1], yrange[2] + 0.25
                ), type="n", xlab="Year", ylab="Sales", bty="l", xaxt="n", yaxt="n")

# Add the time series training set
lines(DeptSales.ts, bty="l")

# Add the x-axis
axis(1, at = seq(1, 7, 1), labels = format(seq(1, 7, 1)))

# Add the y-axis
axis(2, at = seq(40000, 120000, 10000), labels = format(seq(40, 120, 10)), las = 2)

# Add the fitted values to the training set
lines(sesSales$fitted, col="red", lwd=1)

# Use the forecast() function to generate forecasts for the validation period
sesSalesPredictions <- forecast(sesSales, h=validLength, level=0)


# Print them out
sesSalesPredictions

# Add them to the plot
lines(sesSalesPredictions$mean, col="red", lwd=2, lty=2)

# # Add the "visual breakpoints"
abline(v=6)
arrows(1, 103000, 6, 103000, code=3, length=0.1)
text(3, 98000, "Training")
abline(v=7)
arrows(6, 103000, 7, 103000, code=3, length=0.1)
text(6.5, 98000, "Validation")
```


* **Double exponential smoothing of the raw series**
Strictly, **double exponential smoothing** is used to forecast data that has a trend component. As we learned when running the ets() function, the Dept Store Sales data has multiplicative seasonality and no significant trend **MNM**. Therefore double exponential smoothing would not be the optimal model for this series. 

An extension of double exponential smoothing called the  **Holt Winter's** model is appropriate for a data series that has both trend and seasonality components. 

```{r}
plot(stl(DeptSales.ts, t.window = 0, s.window = "periodic"))

```




* **Holt-Winter's exponential smoothing of the raw  series**


**Is there trend?**

```{r}



```


b. A forecaster was tasked to generate forecasts for 4 quarters ahead. She therefore partitioned the data so that the last 4 quarters were designated as the validation period. The forecaster approached the forecasting task by using multiplicative Holt-Winter's exponential smoothing. Specifically, you should call the ets function with the parameters restrict=FALSE, model = "ZZZ" and use the smoothing constants of $\alpha=0.2$ $\alpha=0.2$, $=\beta=0.15$ $\beta=0.15$, and $\lambda=0.05$ $\lambda=0.05$.

i. Run this method on the data. Request the forecasts on the validation period. (Note that the forecasted values for the validation set will be different than what the book shows.)

ii. Using the forecasts for the validation set that you came up with in i. above, 
  *compute the MAPE values for the forecasts of quarters 21-22.
  
c. The fit and the residuals were displayed in the book. 
  *Please reproduce them with R code. Using all the information from (b) and your generated figures, is this model suitable for forecasting quarters 21 and 22?
  
d. Another analyst decided to take a much simpler approach, and instead of using exponential smoothing he used differencing. 

  *Use differencing to remove the trend and seasonal pattern. Which order works better: first removing trend and then seasonality or the opposite order? 

  *Show the progression of time plots as you difference the data and each final series to provide evidence in support of your answer.
  
e. Forecast quarters 21-22 using the average of the double-differenced series from (d). Remember to use only the training period (until quarter 20), and to adjust back for the trend and seasonal pattern.

f. Compare the forecasts from (e) to the exponential smoothing forecasts found in (b). Which of the two forecasting methods would you choose? Explain.

g. What is an even simpler approach that should be compared as a baseline? 
  *Complete that comparison.

8. Forecasting Australian Wine Sales: Figure 5.14 shows time plots of monthly sales of six types of Australian wines (red, rose, sweet white, dry white, sparkling, and fortified) for 1980-1994. Data available in AustralianWines.xls. 23 The units are thousands of liters. You are hired to obtain short-term forecasts (2-3 months ahead) for each of the six series, and this task will be repeated every month.

(a) Which smoothing method would you choose if you had to choose the same method for forecasting all series? Why? 

(b) Fortified wine has the largest market share of the six types of wine. You are asked to focus on fortified wine sales alone and produce as accurate a forecast as possible for the next two months.

  *Start by partitioning the data using the period until Dec- 1993 as the training period. 
  
  *Apply Holt-Winter's exponential smoothing (with multiplicative seasonality) to sales. 
  
(c) Create a plot for the residuals from the Holt-Winter's exponential smoothing. 

**i. Based on this plot, which of the following statements are reasonable?**

  *December"s (month 12) are not captured well by the model. 
  
  *There is a strong correlation between sales on the same calendar month. 
  
  *The model does not capture the seasonality well. 
  *We should first deseasonalize the data and then apply Holt-Winter's exponential smoothing.
  
**ii. How can you handle the above effect with exponential smoothing?**


