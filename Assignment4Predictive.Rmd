---
title: 'Predictive: Unit 4 Quiz and Homework'
author: "Christine Iyer"
date: "March 18, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Quiz:

**1.	Explain what type of smoothing model can be used if a time series contains a trend.**

Moving Average can be used for data that contains trend, if the data series is detrended. One way it can be trended is by using differencing with a lag = 1. If the data reveals an exponential or quadratic trend, a second round of differencing with a lag = 1 may be necessary. 

Simple Exponential Smoothing, like Moving Average, is for forecasting time series that have no trend or seasonality. However if the data series has been detrended with differencing, simple exponential smoothing may be a good model. 

Advanced Expoential Smoothing models are built to accomodate data series with trend. In particular, double exponential smoothing, aka, Holt's linear trend model, the assumption is that the trend can change over time, it's not just assuming the trend is global. Thr trend is estimated from the data and is consistently updated with more data as it becomes available. Holt's model can accomodate data with additive and multiplicative trends. 

A second exponential smoothing method called Holt Winter's is appropriate for data series with trend and seasonality. Again, it can accomodate both additive and multiplicative trends. 

2.	Explain how the value of alpha affects the simple exponential smoothing method.

$\alpha$, a user chosen parameter, operates as a constant and is valued between 0-1; it determines the model's rate of learning, i.e., how much influence the most recent values in the time series have on the forecast. (Alpha operates simliarly to the user determined W, or window length, in moving averages in that it dictates the importance of newer information in generating the forecast.) A value close to 1, causes the model to learn faster,  meaning that the the most recent data has the greatest impact on the forecast. Conversely, a value close to 0 indicates the model  learns slowly and the recent data have little impact while past data have the greatest influence. 

Because $\alpha$ is far from zero, the level adapts locally,



**3.	Explain what it means if the two smoothing constants in double exponential smoothing, alpha and beta, are closer to 1.**

The $\alpha$ constant is used to smooth the time series that exhibits stationarity. As explained above, in exponential smoothing, an $\alpha$ close to one means the model learns quickly and the most recent data in the series has the greatest impact on the forecast. 

$\beta$ is a second smoothing constant that is used in addition to $\alpha$ and it is used in double exponential smoothing, or, Holt Winter's models for **trend** smoothing. A higher $\beta$ value, one that is closer to 1, is chsen when less smoothing is desired; therefore, more weight is plaved on the recent data.  

**4.	Describe how you would use differencing to remove a trend from a time series dataset.**

If a forecaster observes a trend in the time series data, but would like to see how a moving average forecast would perform in terms of predictive accuracy, he would have to use differencing to remove this trend. Moving averages are typically forecasting tools for data that exhibits stationarity, not trend or seasonality. In order to adapt the moving average forecast for data with a linear trend, the user first performs differencing with a lag on 1. Once this is done, a plot of the data will show no visible trend. If the initial data set shows a quadratic or exponential trend, another round of lag-1 differencing is required on the already differenced data. Performing differencing with a lag of 1 is simply done by taking the difference between every 2 consecutive values for the series. 

"One advantage of differencing over other methods (e.g., a regression with a trend - see Chapter 6) is that differencing does not assume that the trend is global: i.e., the trend shape is fixed throughout the entire period."

Shmueli, Galit; Lichtendahl Jr, Kenneth C.. Practical Time Series Forecasting with R: A Hands-On Guide [2nd Edition] (Practical Analytics) (Page 85). Axelrod Schnall Publishers. Kindle Edition. 



**5.	When using moving average for forecasting, how should you choose the appropriate window size, w?**

When using the moving average forecasting model, the user gets to choose the width of the trailing moving average window, or **W**. Striking a balance between under and over forecasting may require some trial and error. A first step is to visualize the data series. If the series shows seasonal pattern, a W of the length of the seasonal cycle may be a good choice. 

Domain knowledge regarding how fast the series changes and regarding the relevance of past observations will assist the forecaster in making this decision. 

Trial and error is also part of the decision. Seeing how the model performs with different window widthe allows comparison of the errors and the performance charts. It is also important to not overfit the model to the data.  


#Homework:

Please answer Chapter 5, questions 2, 5, and 8 from the text (p. 108 - 116).




##2. 
Relationship between Moving Average and Exponential Smoothing: Assume that we apply a moving average to a series, using a very short window span. If we wanted to achieve an equivalent result using simple exponential smoothing, what value should the smoothing constant take?

A value very close to 1. 

#Testing for question 2 on HW

**trailing ma**

```{r}
ridership <- read.csv("Amtrak.csv")
##convert data to a time series
ridership.ts <- ts(ridership$Ridership_in_thousands, start = c(1991,1), end = c(2004, 3), frequency = 12)
```


```{r}
library(zoo)
library(forecast)
#3 year validation period window
nValid <- 36
#training period
nTrain <- length(ridership.ts) - nValid
#training window
train.ts <- window(ridership.ts, start = c(1991, 1), end = c(1991, nTrain))
#validation window
valid.ts <- window(ridership.ts, start = c(1991, nTrain + 1), end = c(1991, nTrain + nValid))
#trailing moving average of training period
ma.trailing <- rollmean(train.ts, k = 12, align = "right")
#last value because want a lag 
#last.ma <- tail(ma.trailing, 1)
#ma.trailing.pred <-ts(rep(last.ma, nValid), start = c(1991, nTrain + 1), end = c(1991, nTrain + nValid), freq = 12)
forecast.ma.trailing <- forecast(ma.trailing, h = nValid, level = 0)
accuracy(forecast.ma.trailing, valid.ts)
```

**ses**
```{r}
ses.ridership <- ets(train.ts, model = "ANN", alpha = .98)


ses.pred <- forecast(ses.ridership, h = nValid, level = 0)
accuracy(ses.pred, valid.ts)
```


##5. 
Forecasting Department Store Sales


```{r}
library(dplyr)
library(forecast)
DeptSales <- read.csv("DeptStoreSales.csv", header = TRUE, stringsAsFactors = FALSE)

DeptSales$Yr_Qtr <- c("Year 1 Q-1", "Year 1 Q-2", "Year 1 Q-3", "Year 1 Q-4", "Year 2 Q-1", "Year 2 Q-2", "Year 2 Q-3", "Year 2 Q-4", "Year 3 Q-1", "Year 3 Q-2", "Year 3 Q-3", "Year 3 Q-4", "Year 4 Q-1", "Year 4 Q-2", "Year 4 Q-3", "Year 4 Q-4", "Year 5 Q-5", "Year 5 Q-2", "Year 5 Q-3", "Year 5 Q-4", "Year 6 Q-1", "Year 6 Q-2", "Year 6 Q-3", "Year 6 Q-4")
DeptSales <- DeptSales %>% select(Yr_Qtr, Sales)
head(DeptSales)
DeptSales.ts <- ts(DeptSales$Sales, start = c(1,1), frequency = 4)
#linear trend line
DeptSales.Linear <- tslm(DeptSales.ts ~ trend)
sales.lm.pred <- forecast(DeptSales.Linear, h = nValid, level = 0)
#quadratic trend line
DeptSales.quad <- tslm(DeptSales.ts ~ trend + I(trend^2))
sales.quad <- forecast(DeptSales.quad, h = nValid, level = 0)


yrange <- range(DeptSales.ts)

plot(c(1,6), yrange, type = "n", xlab = "Year", ylab = "Dept Store Sales (thousands)", bty = "l", xaxt = "n", yaxt = "n")



#



axis(1, at = seq(1, 6, 1), labels = format(seq(1, 6, 1)))
axis(2, at = seq(40000, 105000, 10000), labels = format(seq(40, 105, 10)), las = 2)
lines(DeptSales.Linear$fitted , col = "blue")
lines(DeptSales.quad$fitted, col = "red")
legend(1, 100, c("Dept Store Sales", "Linear Trend", "Quad Trend"), lty = c(1,1,1), col = c("green", "blue", "red"), lwd = c(2,2,2), bty = "n")

#plot(DeptSales.ts, type = "n", xlab = "Year", ylab = "Sales", ylim = c(25000, 105000), bty = "l", col = 3, type = "o", lwd = 2, xaxt = "n", yaxt = "n") 
```


```{r}
yrange <- range(DeptSales.ts)
#plot
plot(c(1,6), yrange, type = "n", xlab = "Year", ylab = "Dept Store Sales (thousands)", bty = "l", xaxt = "n", yaxt = "n")
lines(DeptSales.ts, bty = "l", lwd = 2)
axis(1, at = seq(1, 6, 1), labels = format(seq(1, 6, 1)))
axis(2, at = seq(40000, 105000, 10000), labels = format(seq(40000, 105000, 10000)), las = 2)
lines(DeptSales.Linear$fitted , col = "blue")
lines(DeptSales.quad$fitted, col = "green")
legend(1, 105000, c("Dept Store Sales", "Linear Trend", "Quadratic Trend"), lty = c(1,1,1), col = c("black", "blue", "green"), lwd = c(2,2,2), bty = "n")






```



lines(trailingMA, col = "blue", lwd = 2)
lines(centeredMA, col = "green", lwd = 2)
legend(1, 100, c("Dept Store Sales", "Trailing Moving Average", "Centered Moving Average"), lty = c(1,1,1), col = c("black", "blue", "green"), lwd = c(2,2,2), bty = "n")

```{r}

#linear summary
summary(DeptSales.Linear)
#Quad Summary
summary(sales.quad)
par(mfrow = c(2, 1)) 
#plot series
plot(DeptSales.ts, xlab = "Time", ylab = "DeptSales", #ylim = c(40, 100), 
     bty = "l") 
#plot fitted trend line
#lines(DeptSales.lm$fitted, lwd = 2) 
#zoom into 4 years
#first create window
DeptSales.ts.zoom <- window(DeptSales.ts, start = c(1, 1), end = c(3, 4))
#plot zooned in data
plot(DeptSales.ts.zoom, xlab = "Time", ylab = "Dept Store Sales", ylim = c(25000, 105000), bty = "l") 


```

```{r, echo=TRUE}

ggseasonplot(DeptSales.ts, ylab = "DeptSales", main = "Seasonal Plot for Dept Store Sales") 
#+ guides(fill = guide_legend(reverse = TRUE)) 
#+ theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
```

**Ridership boken out by month**

```{r}

par(oma = c(0, 0, 0, 2))
xrange <- c(1992,2004)
yrange <- range(ridership.ts)
plot(xrange, yrange, type="n", xlab="Year", ylab="Monthly Plot Dept Store Sales ", bty="l", las=1)
colors <- rainbow(12) 
linetype <- c(1:12) 
plotchar <- c(1:12)
axis(1, at=seq(1992,2004,1), labels=format(seq(1992,2004,1)))
for (i in 1:12) { 
  currentMonth <- subset(ridership.ts, cycle(ridership.ts)==i)
  lines(seq(1992, 1992 +length(currentMonth)-1,1), currentMonth, type="b", lwd=1,
      lty=linetype[i], col=colors[i], pch=plotchar[i]) 
} 
title("Ridership Broken Out by Month")
legend(2002.35, 80, 1:12, cex=0.8, col=colors, pch=plotchar, lty=linetype, title="Month", xpd=NA)



```


```{r}



```


a. Which of the following methods would not be suitable for forecasting this series. Explain why or why not for each one.

**Moving average of raw series** This is not a method for forecasting because it does not accomodate trend or seasonality, 2 components in this data series.  

Forecast the data with a trailing moving average

```{r}
validLength <- 4
trainLength <- length(DeptSales.ts) - validLength
salesTrain <- window(DeptSales.ts, end = c(1, trainLength))
salesValid <- window(DeptSales.ts, start = c(1, trainLength + 1))
#trailing moving average
trailingMA <- rollmean(salesTrain, k = 3, align = "right")
trailingMA[1]
centeredMA <- ma(salesTrain, order = 3)
forecast(trailingMA, h = validLength)
#accuracy(forecast(trailingMA, h = validLength))
yrange <- range(DeptSales.ts)
#plot
plot(c(1,6), yrange, type = "n", xlab = "Year", ylab = "Dept Store Sales (thousands)", bty = "l", xaxt = "n", yaxt = "n")
lines(DeptSales.ts, bty = "l", lwd = 2)
axis(1, at = seq(1, 6, 1), labels = format(seq(1, 6, 1)))
yrange
#seq() from, to, by in increments
axis(2, at = seq(40000, 105000, 10000), labels = format(seq(40, 105, 10)), las = 2)
lines(trailingMA, col = "blue", lwd = 2)
lines(centeredMA, col = "green", lwd = 2)
legend(1, 100, c("Dept Store Sales", "Trailing Moving Average", "Centered Moving Average"), lty = c(1,1,1), col = c("black", "blue", "green"), lwd = c(2,2,2), bty = "n")
```


* Moving average of deseasonalized series 

```{r}
#difference the quarterly series for seasonality. lag = 4
#set up a plot with 2 rows and 2 columns
par(mfrow = c(2,2))
#plot the original
plot(DeptSales.ts, ylab = "Dept Store Sales", xlab = "Year", bty = "l", main = "Dept Store Sales")
#plot the lag-4 difference
plot(diff(DeptSales.ts, lag = 4), ylab="Lag-4", xlab="Year", bty="l", main="Lag-4 Difference")
plot(diff(DeptSales.ts, lag = 1), ylab="Lag-1", xlab="Year", bty="l", main="Lag-1 Difference")
#plot(diff(diff(DeptSales.ts), lag = 4), lag = 1)

lag4and1 <- diff(diff(DeptSales.ts, lag = 4), lag = 1)
plot(lag4and1, ylab="Lag-4, then Lag-1", xlab="Year", bty="l", main="Twice-Differenced (Lag-4, Lag-1)")

```


* Simple exponential smoothing of the raw series 
* Double exponential smoothing of the raw series 
* Holt-Winter's exponential smoothing of the raw series


**Is there trend?**

```{r}



```


b. A forecaster was tasked to generate forecasts for 4 quarters ahead. She therefore partitioned the data so that the last 4 quarters were designated as the validation period. The forecaster approached the forecasting task by using multiplicative Holt-Winter's exponential smoothing. Specifically, you should call the ets function with the parameters restrict=FALSE, model = "ZZZ" and use the smoothing constants of $\alpha=0.2$ $\alpha=0.2$, $=\beta=0.15$ $\beta=0.15$, and $\lambda=0.05$ $\lambda=0.05$.

i. Run this method on the data. Request the forecasts on the validation period. (Note that the forecasted values for the validation set will be different than what the book shows.)

ii. Using the forecasts for the validation set that you came up with in i. above, 
  *compute the MAPE values for the forecasts of quarters 21-22.
  
c. The fit and the residuals were displayed in the book. 
  *Please reproduce them with R code. Using all the information from (b) and your generated figures, is this model suitable for forecasting quarters 21 and 22?
  
d. Another analyst decided to take a much simpler approach, and instead of using exponential smoothing he used differencing. 

  *Use differencing to remove the trend and seasonal pattern. Which order works better: first removing trend and then seasonality or the opposite order? 

  *Show the progression of time plots as you difference the data and each final series to provide evidence in support of your answer.
  
e. Forecast quarters 21-22 using the average of the double-differenced series from (d). Remember to use only the training period (until quarter 20), and to adjust back for the trend and seasonal pattern.

f. Compare the forecasts from (e) to the exponential smoothing forecasts found in (b). Which of the two forecasting methods would you choose? Explain.

g. What is an even simpler approach that should be compared as a baseline? 
  *Complete that comparison.

8. Forecasting Australian Wine Sales: Figure 5.14 shows time plots of monthly sales of six types of Australian wines (red, rose, sweet white, dry white, sparkling, and fortified) for 1980-1994. Data available in AustralianWines.xls. 23 The units are thousands of liters. You are hired to obtain short-term forecasts (2-3 months ahead) for each of the six series, and this task will be repeated every month.

(a) Which smoothing method would you choose if you had to choose the same method for forecasting all series? Why? 

(b) Fortified wine has the largest market share of the six types of wine. You are asked to focus on fortified wine sales alone and produce as accurate a forecast as possible for the next two months.

  *Start by partitioning the data using the period until Dec- 1993 as the training period. 
  
  *Apply Holt-Winter's exponential smoothing (with multiplicative seasonality) to sales. 
  
(c) Create a plot for the residuals from the Holt-Winter's exponential smoothing. 

**i. Based on this plot, which of the following statements are reasonable?**

  *December"s (month 12) are not captured well by the model. 
  
  *There is a strong correlation between sales on the same calendar month. 
  
  *The model does not capture the seasonality well. 
  *We should first deseasonalize the data and then apply Holt-Winter's exponential smoothing.
  
**ii. How can you handle the above effect with exponential smoothing?**


